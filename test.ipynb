{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = torch.log(torch.tensor(1e2)) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_embedding: torch.Size([1024, 128])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "label must be scalar or have the same length as the input data, but found 1024 for 128 datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     labels\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m---> 41\u001b[0m plt\u001b[39m.\u001b[39;49mplot(pos_embedding, label\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m     42\u001b[0m \u001b[39m# plt.legend()\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[39m# plt.imshow(res)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:530\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m n_datasets \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m cbook\u001b[39m.\u001b[39mis_scalar_or_string(label):\n\u001b[1;32m    529\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(label) \u001b[39m!=\u001b[39m n_datasets:\n\u001b[0;32m--> 530\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlabel must be scalar or have the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength as the input data, but found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(label)\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mn_datasets\u001b[39m}\u001b[39;00m\u001b[39m datasets.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    533\u001b[0m     labels \u001b[39m=\u001b[39m label\n\u001b[1;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: label must be scalar or have the same length as the input data, but found 1024 for 128 datasets."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def embed(self, p, dim):\n",
    "        half_dim = dim // 2\n",
    "        embeddings = torch.log(torch.tensor(self.dim//16)) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=p.device) * -embeddings)\n",
    "        embeddings = p[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "    def forward(self, p_x, p_y):\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings_x = self.embed(p_x, half_dim)\n",
    "        embeddings_y = self.embed(p_y, half_dim)\n",
    "        embeddings = torch.cat((embeddings_x, embeddings_y), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "\n",
    "img_size = 1024\n",
    "patch_size = 32\n",
    "patches_in_row = img_size//patch_size\n",
    "n_patches = (patches_in_row) ** 2\n",
    "\n",
    "p_x = torch.arange(patches_in_row)\n",
    "p_y = torch.arange(patches_in_row)\n",
    "poses = torch.cartesian_prod(p_x, p_y)\n",
    "\n",
    "sembed = SinusoidalPositionEmbeddings(dim=128)\n",
    "pos_embedding = sembed(poses[:,0], poses[:,1])\n",
    "print(f\"pos_embedding: {pos_embedding.shape}\")\n",
    "\n",
    "labels = []\n",
    "for i, j in poses:\n",
    "    labels.append(f\"({i}, {j})\")\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "plt.plot(pos_embedding, label=labels)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.imshow(res)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        patch_size: Tuple[int, int],\n",
    "        latent_size: int,\n",
    "        hw_size: Tuple[int, int],\n",
    "        n_channel: int,\n",
    "        batch_size: int,\n",
    "        device: torch.device.type,\n",
    "        *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.linear_projection = nn.Linear(patch_size[0]*patch_size[1]*n_channel, latent_size)\n",
    "        self.segment_token = nn.Parameter(torch.randn(batch_size, 1, latent_size), requires_grad=True).to(device)\n",
    "        \n",
    "        p_r = torch.arange(1, hw_size[0]//patch_size[0]+1)\n",
    "        p_c = torch.arange(1, hw_size[1]//patch_size[1]+1)\n",
    "        poses = torch.cartesian_prod(p_r, p_c)+1\n",
    "        poses = torch.concat([torch.zeros((1, 2)), poses], dim=0)\n",
    "        sembed = SinusoidalPositionEmbeddings(dim=latent_size)\n",
    "        self.pos_embedding = sembed(poses[:,0], poses[:,1]).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        patches = einops.rearrange(\n",
    "            x, \n",
    "            \"b c (h h1) (w w1) -> b (h w) (h1 w1 c)\", \n",
    "            h1=self.patch_size[0], w1=self.patch_size[1]\n",
    "        )\n",
    "        projected_patches = self.linear_projection(patches)\n",
    "        x = torch.concat([self.segment_token, projected_patches], dim=1)\n",
    "        pos_embedding = einops.repeat(self.pos_embedding, \"p d -> b p d\", b=x.shape[0])\n",
    "        \n",
    "        print(x.shape, pos_embedding.shape)\n",
    "        x += pos_embedding\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1025, 64]) torch.Size([8, 1025, 64])\n",
      "input shape: torch.Size([8, 3, 1024, 1024]), output shape: torch.Size([8, 1025, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(8, 3, 1024, 1024))\n",
    "\n",
    "embedder = PatchEmbedding(\n",
    "    patch_size=(32, 32),\n",
    "    latent_size = 64,\n",
    "    hw_size = (1024, 1024),\n",
    "    n_channel = 3,\n",
    "    batch_size = 8,\n",
    "    device = \"cpu\"\n",
    ")\n",
    "\n",
    "y = embedder(x)\n",
    "\n",
    "print(f\"input shape: {x.shape}, output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
